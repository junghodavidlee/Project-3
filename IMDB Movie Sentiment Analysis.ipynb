{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into target and features\n",
    "X = data['review']\n",
    "y = data['sentiment']\n",
    "# Do a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=250),\n",
    "    keras.layers.LSTM(64, return_sequences=True),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=250),\n",
    "    keras.layers.LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(16, activation=LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 120ms/step - accuracy: 0.6286 - loss: 0.6151 - val_accuracy: 0.8621 - val_loss: 0.3330\n",
      "Epoch 2/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 120ms/step - accuracy: 0.8583 - loss: 0.3363 - val_accuracy: 0.8774 - val_loss: 0.2888\n",
      "Epoch 3/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 124ms/step - accuracy: 0.8860 - loss: 0.2841 - val_accuracy: 0.8841 - val_loss: 0.2742\n",
      "Epoch 4/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 114ms/step - accuracy: 0.8987 - loss: 0.2537 - val_accuracy: 0.8888 - val_loss: 0.2779\n",
      "Epoch 5/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 118ms/step - accuracy: 0.9075 - loss: 0.2323 - val_accuracy: 0.8863 - val_loss: 0.2689\n",
      "Epoch 6/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 119ms/step - accuracy: 0.9088 - loss: 0.2320 - val_accuracy: 0.8883 - val_loss: 0.2765\n",
      "Epoch 7/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 115ms/step - accuracy: 0.9134 - loss: 0.2201 - val_accuracy: 0.8872 - val_loss: 0.2666\n",
      "Epoch 8/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 118ms/step - accuracy: 0.9176 - loss: 0.2062 - val_accuracy: 0.8893 - val_loss: 0.2733\n",
      "Epoch 9/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 117ms/step - accuracy: 0.9207 - loss: 0.2021 - val_accuracy: 0.8849 - val_loss: 0.2808\n",
      "Epoch 10/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 125ms/step - accuracy: 0.9212 - loss: 0.1987 - val_accuracy: 0.8834 - val_loss: 0.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20ef0391760>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(review):\n",
    "    encoded_review = tokenizer.texts_to_sequences([review])\n",
    "    padded_review = pad_sequences(encoded_review, maxlen=250, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded_review)\n",
    "    return prediction\n",
    "    #return \"Positive\" if prediction > 0.5 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "sample_review = \"This movie was absolutely fantastic! The storyline was engaging and the characters were well developed.\"\n",
    "print(predict_review(sample_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step\n",
      "Confusion Matrix:\n",
      " [[4453  508]\n",
      " [ 620 4419]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      4961\n",
      "           1       0.90      0.88      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Accuracy: 0.8872\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "[[0.24143018]]\n"
     ]
    }
   ],
   "source": [
    "sample_review = \"\"\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\"\"\n",
    "print(predict_review(sample_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "[[0.48245373]]\n"
     ]
    }
   ],
   "source": [
    "sample_review2 = \"\"\"I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. I do not recommend this film.\"\"\"\n",
    "print(predict_review(sample_review2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio interface\n",
    "import gradio as gr\n",
    "\n",
    "func = gr.Interface(\n",
    "    fn=predict_review, \n",
    "    inputs=gr.Textbox(\n",
    "    label=\"Enter your review here\",\n",
    "    lines=3,\n",
    "    max_lines=5,\n",
    "    interactive=True  \n",
    "), \n",
    "    outputs=gr.Textbox(label='Review')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n"
     ]
    }
   ],
   "source": [
    "func.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "# Example review\n",
    "review = \"The Dark Knight was an amazing movie, and Christian Bale was outstanding.\"\n",
    "\n",
    "# Get named entities\n",
    "entities = ner_pipeline(review)\n",
    "\n",
    "# Print results\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Score: {entity['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet', 'test': 'test.parquet'}\n",
    "df_new = pd.read_parquet(\"hf://datasets/cornell-movie-review-data/rotten_tomatoes/\" + splits[\"train\"], engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.rename(columns={'text': 'review'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForTokenClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m----> 8\u001b[0m ner_pipeline \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Use GPU if available\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Process reviews in batches\u001b[39;00m\n\u001b[0;32m     11\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# Adjust based on memory\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0)  # Use GPU if available\n",
    "\n",
    "# Process reviews in batches\n",
    "batch_size = 32  # Adjust based on memory\n",
    "reviews = df_new[\"review\"].tolist()\n",
    "\n",
    "# Apply NER in batches\n",
    "all_entities = []\n",
    "for i in tqdm(range(0, len(reviews), batch_size)):\n",
    "    batch = reviews[i : i + batch_size]\n",
    "    results = ner_pipeline(batch)\n",
    "    all_entities.extend(results)\n",
    "\n",
    "df_new[\"named_entities\"] = all_entities\n",
    "df_new.to_csv(\"movie_reviews_with_entities.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"movie_reviews_with_entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'entity': 'B-PER', 'score': 0.92304903, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  the rock is destined to be the 21st century's ...      1   \n",
       "1  the gorgeously elaborate continuation of \" the...      1   \n",
       "2                     effective but too-tepid biopic      1   \n",
       "3  if you sometimes like to go to the movies to h...      1   \n",
       "4  emerges as something rare , an issue movie tha...      1   \n",
       "\n",
       "                                      named_entities  \n",
       "0                                                 []  \n",
       "1  [{'entity': 'B-PER', 'score': 0.92304903, 'ind...  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'entity': 'B-PER', 'score': 0.92304903, 'index': 31, 'word': 'pet', 'start': 155, 'end': 158}, {'entity': 'B-PER', 'score': 0.9222884, 'index': 33, 'word': 'jack', 'start': 161, 'end': 165}, {'entity': 'B-PER', 'score': 0.41237748, 'index': 47, 'word': '##lk', 'start': 204, 'end': 206}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to have fun , wasabi is a good place to start .</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>any enjoyment will be hinge from a personal threshold of watching sad but endearing characters do extremely unconventional things .</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>if legendary shlockmeister ed wood had ever made a movie about a vampire , it probably would look a lot like this alarming production , adapted from anne rice's novel the vampire chronicles .</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>hardly a nuanced portrait of a young woman's breakdown , the film nevertheless works up a few scares .</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>interminably bleak , to say nothing of boring .</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>things really get weird , though not particularly scary : the movie is all portent and no content .</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                  review  \\\n",
       "0                                                      the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .   \n",
       "1     the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .   \n",
       "2                                                                                                                                                                                                         effective but too-tepid biopic   \n",
       "3                                                                                                                                              if you sometimes like to go to the movies to have fun , wasabi is a good place to start .   \n",
       "4                                                                                                                        emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .   \n",
       "...                                                                                                                                                                                                                                  ...   \n",
       "8525                                                                                                 any enjoyment will be hinge from a personal threshold of watching sad but endearing characters do extremely unconventional things .   \n",
       "8526                                     if legendary shlockmeister ed wood had ever made a movie about a vampire , it probably would look a lot like this alarming production , adapted from anne rice's novel the vampire chronicles .   \n",
       "8527                                                                                                                              hardly a nuanced portrait of a young woman's breakdown , the film nevertheless works up a few scares .   \n",
       "8528                                                                                                                                                                                     interminably bleak , to say nothing of boring .   \n",
       "8529                                                                                                                                 things really get weird , though not particularly scary : the movie is all portent and no content .   \n",
       "\n",
       "      label  \\\n",
       "0         1   \n",
       "1         1   \n",
       "2         1   \n",
       "3         1   \n",
       "4         1   \n",
       "...     ...   \n",
       "8525      0   \n",
       "8526      0   \n",
       "8527      0   \n",
       "8528      0   \n",
       "8529      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         named_entities  \n",
       "0                                                                                                                                                                                                                                                                                                    []  \n",
       "1     [{'entity': 'B-PER', 'score': 0.92304903, 'index': 31, 'word': 'pet', 'start': 155, 'end': 158}, {'entity': 'B-PER', 'score': 0.9222884, 'index': 33, 'word': 'jack', 'start': 161, 'end': 165}, {'entity': 'B-PER', 'score': 0.41237748, 'index': 47, 'word': '##lk', 'start': 204, 'end': 206}]  \n",
       "2                                                                                                                                                                                                                                                                                                    []  \n",
       "3                                                                                                                                                                                                                                                                                                    []  \n",
       "4                                                                                                                                                                                                                                                                                                    []  \n",
       "...                                                                                                                                                                                                                                                                                                 ...  \n",
       "8525                                                                                                                                                                                                                                                                                                 []  \n",
       "8526                                                                                                                                                                                                                                                                                                 []  \n",
       "8527                                                                                                                                                                                                                                                                                                 []  \n",
       "8528                                                                                                                                                                                                                                                                                                 []  \n",
       "8529                                                                                                                                                                                                                                                                                                 []  \n",
       "\n",
       "[8530 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_reviews \u001b[38;5;241m=\u001b[39m df_reviews[df_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamed_entities\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m      2\u001b[0m df_reviews\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "df_reviews = df_reviews[df_reviews['named_entities'].apply(lambda x: len(x) > 2)]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# List of movie reviews\n",
    "reviews = df_reviews[\"review\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each review and extract entities\n",
    "for review in reviews:\n",
    "    doc = nlp(review)\n",
    "    print(f\"Review: {review}\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"  Entity: {ent.text}, Label: {ent.label_}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_imdb = data[\"review\"].tolist()\n",
    "# Process each review and extract entities\n",
    "for review in reviews_imdb:\n",
    "    doc = nlp(review)\n",
    "    print(f\"Review: {review}\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"  Entity: {ent.text}, Label: {ent.label_}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in reviews:\n",
    "    count = 0\n",
    "    doc = nlp(review)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            count += 1\n",
    "    df_reviews['count'][review] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 review  label count\n",
      "0     the rock is destined to be the 21st century's ...      1     2\n",
      "1     the gorgeously elaborate continuation of \" the...      1     2\n",
      "2                        effective but too-tepid biopic      1     0\n",
      "3     if you sometimes like to go to the movies to h...      1     0\n",
      "4     emerges as something rare , an issue movie tha...      1     0\n",
      "...                                                 ...    ...   ...\n",
      "8525  any enjoyment will be hinge from a personal th...      0     0\n",
      "8526  if legendary shlockmeister ed wood had ever ma...      0     2\n",
      "8527  hardly a nuanced portrait of a young woman's b...      0     0\n",
      "8528    interminably bleak , to say nothing of boring .      0     0\n",
      "8529  things really get weird , though not particula...      0     0\n",
      "\n",
      "[8530 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataFrame using `iterrows()`\n",
    "for idx, row in df_reviews.iterrows():\n",
    "    count = 0\n",
    "    doc = nlp(row[\"review\"])  # Process the review text\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            count += 1\n",
    "    df_reviews.at[idx, \"count\"] = count  # Assign count correctly\n",
    "print(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "0    3626\n",
       "1     528\n",
       "2      94\n",
       "3      13\n",
       "4       3\n",
       "5       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_positive = df_reviews.drop(df_reviews[df_reviews['label'] == 0].index)\n",
    "df_reviews_positive['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "0    3710\n",
       "1     489\n",
       "2      55\n",
       "3      10\n",
       "4       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_negative = df_reviews.drop(df_reviews[df_reviews['label'] == 1].index)\n",
    "df_reviews_negative['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['all_entities_count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 review  label count  \\\n",
      "0     the rock is destined to be the 21st century's ...      1     2   \n",
      "1     the gorgeously elaborate continuation of \" the...      1     2   \n",
      "2                        effective but too-tepid biopic      1     0   \n",
      "3     if you sometimes like to go to the movies to h...      1     0   \n",
      "4     emerges as something rare , an issue movie tha...      1     0   \n",
      "...                                                 ...    ...   ...   \n",
      "8525  any enjoyment will be hinge from a personal th...      0     0   \n",
      "8526  if legendary shlockmeister ed wood had ever ma...      0     2   \n",
      "8527  hardly a nuanced portrait of a young woman's b...      0     0   \n",
      "8528    interminably bleak , to say nothing of boring .      0     0   \n",
      "8529  things really get weird , though not particula...      0     0   \n",
      "\n",
      "     all_entities_count  \n",
      "0                     3  \n",
      "1                     2  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "...                 ...  \n",
      "8525                  0  \n",
      "8526                  2  \n",
      "8527                  0  \n",
      "8528                  0  \n",
      "8529                  0  \n",
      "\n",
      "[8530 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_reviews.iterrows():\n",
    "    count = 0\n",
    "    doc = nlp(row[\"review\"])\n",
    "    for ent in doc.ents:\n",
    "        count += 1\n",
    "    df_reviews.at[idx, \"all_entities_count\"] = count\n",
    "print(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_entities_count\n",
       "0    2639\n",
       "1    1108\n",
       "2     381\n",
       "3     104\n",
       "4      22\n",
       "5       8\n",
       "6       2\n",
       "7       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_positive2 = df_reviews.drop(df_reviews[df_reviews['label'] == 0].index)\n",
    "df_reviews_positive2['all_entities_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_entities_count\n",
       "0    2850\n",
       "1    1017\n",
       "2     286\n",
       "3      83\n",
       "4      24\n",
       "5       4\n",
       "6       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_negative2 = df_reviews.drop(df_reviews[df_reviews['label'] == 1].index)\n",
    "df_reviews_negative2['all_entities_count'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
